---
title: "PFER2"
author: "Amber Crozier"
date: "2024-11-18"
output: html_document
---

```{r loading packages, echo=TRUE}
library(corrplot)
library(car)
library(pROC)
library(leaps)
library(openxlsx)
library(glmnet)
library(dplyr)
library(psych)
library(pls)
library(ggplot2)
library(tidymodels)
library(broom)
library(yardstick)
library(caTools)
library(forecast)
library(tree)
library(ISLR2)
library(caret)
library(randomForest)
library(BART)
library(gbm)
library(xgboost)
library(e1071)
library(readxl)
library(reshape2)
library(scales)

data <- read.csv("~/GitHub/DSE6311/encoded_data.csv")
```


```{r normalize, echo=TRUE}
# Min-Max Scaling (Normalize)
min_max_scaled_data <- as.data.frame(lapply(data, function(x) rescale(x, to = c(0, 1))))

# Standardization (Z-Score Scaling)
standardized_data <- as.data.frame(scale(data))

# View the scaled data
head(min_max_scaled_data)
head(standardized_data)
```

```{r subset selection, echo=TRUE}
# Best subset selection
regfit.full <- regsubsets(AI_Satisfaction ~ ., data = data, nvmax = 21)
reg.summary <- summary(regfit.full)
names(reg.summary)
reg.summary$rsq
plot(reg.summary$rss, xlab = "Numbers of Variables", ylab = "RSS")
plot(reg.summary$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq")
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp")


which.min(reg.summary$cp)
points(17, reg.summary$cp[21], col = "red", cex = 2, pch = 21)

# Plot the regression fit with Cp
plot(regfit.full, scale = "Cp")

# Extract the coefficients of the model with 11 variables
coef(regfit.full, 17)
```


```{r CalcSPlitRatio-3, echo=TRUE}
## Code from Geist (2019)
calcSplitRatio <- function(data, p = 21) {
  ## @p  = the number of parameters. by default, if none are provided, the number of columns (predictors) in the dataset are used
  ## @df = the dataframe that will be used for the analysis
  
  ## If the number of parameters isn't supplied, set it to the number of features minus 1 for the target

  ## Calculate the ideal number of testing set
  test_N <- (1 / sqrt(p)) * nrow(data)
  
  ## Turn that into a testing proportion
  test_prop <- round(test_N / nrow(data), 2)
  
  ## And find the training proportion
  train_prop <- 1 - test_prop
  
  ## Output the ideal split ratio
  message("The ideal split ratio is ", train_prop, ":", test_prop, " (training:testing)")
  
  ## Return training set proportion
  return(train_prop)
}

# Final split
calcSplitRatio(data)
```


```{r heatmap, echo=TRUE}
# AC: Calculate the correlation matrix
cor_matrix <- cor(data[, -which(names(data) == "AI_Satisfaction")], use = "pairwise.complete.obs")

# AC: Reshape the correlation matrix into long format
cor_melt <- melt(cor_matrix)

# AC: Create the heatmap
ggplot(data = cor_melt, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0,
                       name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Correlation Matrix Heatmap",
       x = NULL,
       y = NULL)
```


```{r split data, echo=TRUE}
# AC: Create a stratified split for training and testing data (e.g., 78-22 split)
set.seed(123)  
train_index <- createDataPartition(data$AI_Satisfaction, p = 0.78, list = FALSE)

# AC: Split the data
train <- data[train_index, ]
test <- data[-train_index, ]
```



```{r satisfaction recipe, echo=TRUE}
# Convert AI_Satisfaction to a factor in the training data
train$AI_Satisfaction <- as.factor(train$AI_Satisfaction)

# Define recipe for preprocessing
satisfaction_recipe <- recipe(
  AI_Satisfaction ~ Country + Payment_Method_Credit_Debit + Online_Service_Preference + 
    AI_Enhance_Experience + Payment_Method_COD + Payment_Method_Ewallet + Product_Category_Appliances +
    Product_Category_Electronics + Product_Category_Groceries + Product_Category_Personal_Care +
    Product_Category_Clothing + Age + Living_Region + Annual_Salary + Gender + Education + AI_Usage +
    AI_Trust + AI_Tools_Used_Chatbots + AI_Tools_Used_Voice_Photo + AI_Tools_Used_Virtual_Assistant, 
  data = train
) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep(training = train)

logreg_fit <- 
  logistic_reg() %>%
  set_engine("glm") %>%
  fit(AI_Satisfaction ~ ., data = bake(satisfaction_recipe, new_data = train))
logreg_fit

test_baked <- bake(satisfaction_recipe, new_data = test, all_predictors())

# Check the prediction output column names
predicted_probs <- predict(logreg_fit, new_data = test_baked, type = "prob")
print(names(predicted_probs))

# Create a dataframe 'test_results' containing observed values and predicted probabilities
test_results <- 
  dplyr::select(test, AI_Satisfaction) %>%
  bind_cols(
    predict(logreg_fit, new_data = test_baked, type = "prob") %>%
      dplyr::select(p_1 = .pred_1)
  )

# Summary of the results
summary(test_results)

# Check the distribution of the predicted classes ("YES"/"NO")
table(test_results$type)
```


```{r ROC log, echo=TRUE}
################################### plot ROC curve ###################################

## initialze a new dataframe to store FPR & TPR for different prob thresholds
roc_data <- data.frame(threshold=seq(1,0,-0.01), fpr=0, tpr=0)
for (i in roc_data$threshold) {
  
  over_threshold <- test_results[test_results$p_1 >= i, ]
  
  fpr <- sum(over_threshold$AI_Satisfaction==0)/sum(test_results$AI_Satisfaction==0)
  roc_data[roc_data$threshold==i, "fpr"] <- fpr
  
  tpr <- sum(over_threshold$AI_Satisfaction==1)/sum(test_results$AI_Satisfaction==1)
  roc_data[roc_data$threshold==i, "tpr"] <- tpr
  
}

ggplot() +
  geom_line(data = roc_data, aes(x = fpr, y = tpr, color = threshold), linewidth = 3) +
  scale_color_gradientn(colors = rainbow(3)) +
  geom_smooth(data = roc_data, aes(x = fpr, y = tpr), method = "loess", span = 0.3) +
  geom_abline(intercept = 0, slope = 1, lty = 2) +
  geom_point(data = roc_data[seq(1, 101, 10), ], aes(x = fpr, y = tpr)) +
  geom_text(data = roc_data[seq(1, 101, 10), ],
            aes(x = fpr, y = tpr, label = threshold, hjust = 1.2, vjust = -0.2))


################################### ROC curve calculation breakdown ###################################

ggplot(data = test_results, aes(x = p_1, y = AI_Satisfaction)) +
  geom_jitter()

threshold <- 0.78

test_results$predictions <- ifelse(test_results$p_1 >= threshold, 1, 0)
tp <- nrow(test_results[test_results$AI_Satisfaction==1 & test_results$predictions==1, ])
fp <- nrow(test_results[test_results$AI_Satisfaction==0 & test_results$predictions==1, ])
tn <- nrow(test_results[test_results$AI_Satisfaction==0 & test_results$predictions==0, ])
fn <- nrow(test_results[test_results$AI_Satisfaction==1 & test_results$predictions==0, ])

test_results$type <- ""
test_results[test_results$AI_Satisfaction==1 & test_results$predictions==1, "type"] <- "tp"
test_results[test_results$AI_Satisfaction==0 & test_results$predictions==1, "type"] <- "fp"
test_results[test_results$AI_Satisfaction==0 & test_results$predictions==0, "type"] <- "tn"
test_results[test_results$AI_Satisfaction==1 & test_results$predictions==0, "type"] <- "fn"

ggplot(data = test_results, aes(x = p_1, y = AI_Satisfaction)) +
  geom_jitter(aes(colour = type)) +
  geom_vline(xintercept = threshold, linetype = "dashed", color = "blue", linewidth = 1.5) +
  scale_color_brewer(palette = "RdYlBu")

fpr <- fp/(fp + tn)
tpr <- tp/(tp + fn)

# Display confusion matrix for logistic regression model
test_results$predictions <- as.factor(test_results$predictions)

# Convert AI_Satisfaction and predictions to factors with consistent levels
test_results <- test_results %>%
  mutate(
    AI_Satisfaction = as.factor(AI_Satisfaction),
    predictions = as.factor(predictions)
  )

# Display confusion matrix for logistic regression model
conf_mat <- test_results %>%
  conf_mat(truth = AI_Satisfaction, estimate = predictions)
conf_mat

# Calculate ROC and AUC
roc_obj <- roc(
  response = test_results$AI_Satisfaction,
  predictor = test_results$p_1,
  levels = c("0", "1")
)

# Display AUC
auc_value <- auc(roc_obj)
print(auc_value)
```